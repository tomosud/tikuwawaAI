import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import json
import os
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
import pickle


class ChihuawaChikuwaDataset(Dataset):
    """ãƒãƒ¯ãƒ¯ vs ãƒã‚¯ãƒ¯åˆ†é¡ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, paths, labels, transform=None):
        self.paths = paths
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.paths)
    
    def __getitem__(self, idx):
        # ç”»åƒãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã«å¤‰æ›ï¼‰
        image_path = self.paths[idx].replace('\\', '/')
        
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ {image_path}: {e}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”»åƒã‚’ä½œæˆ
            image = Image.new('RGB', (224, 224), color=(128, 128, 128))
        
        if self.transform:
            image = self.transform(image)
        
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        return image, label


class ChihuawaChikuwaClassifier:
    """ãƒãƒ¯ãƒ¯ vs ãƒã‚¯ãƒ¯åˆ†é¡å™¨ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, num_classes=2, device=None):
        self.num_classes = num_classes
        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
        
        print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
    
    def create_model(self):
        """ResNet18ãƒ™ãƒ¼ã‚¹ã®è»¢ç§»å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        # äº‹å‰å­¦ç¿’æ¸ˆã¿ResNet18ã‚’ãƒ­ãƒ¼ãƒ‰
        self.model = models.resnet18(pretrained=True)
        
        # ç‰¹å¾´æŠ½å‡ºå±¤ã‚’å‡çµï¼ˆè»¢ç§»å­¦ç¿’ï¼‰
        for param in self.model.parameters():
            param.requires_grad = False
        
        # æœ€çµ‚åˆ†é¡å±¤ã®ã¿å­¦ç¿’å¯èƒ½ã«è¨­å®š
        num_features = self.model.fc.in_features
        self.model.fc = nn.Linear(num_features, self.num_classes)
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
        self.model = self.model.to(self.device)
        
        print(f"ResNet18ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ (å‡ºåŠ›ã‚¯ãƒ©ã‚¹æ•°: {self.num_classes})")
        return self.model
    
    def create_data_transforms(self):
        """ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚’å®šç¾©"""
        # ImageNetæ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        normalize = transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
        
        # å­¦ç¿’ç”¨å¤‰æ›ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚ã‚Šï¼‰
        train_transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomCrop(224),
            transforms.RandomHorizontalFlip(0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            normalize
        ])
        
        # æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆç”¨å¤‰æ›ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãªã—ï¼‰
        val_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            normalize
        ])
        
        return train_transform, val_transform
    
    def load_data(self, data_split_path='processed_data/data_split.json'):
        """ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
        with open(data_split_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        split_data = data['split_data']
        
        # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚’ä½œæˆ
        train_transform, val_transform = self.create_data_transforms()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
        train_dataset = ChihuawaChikuwaDataset(
            split_data['train']['paths'],
            split_data['train']['labels'],
            transform=train_transform
        )
        
        val_dataset = ChihuawaChikuwaDataset(
            split_data['val']['paths'],
            split_data['val']['labels'],
            transform=val_transform
        )
        
        test_dataset = ChihuawaChikuwaDataset(
            split_data['test']['paths'],
            split_data['test']['labels'],
            transform=val_transform
        )
        
        # DataLoaderã‚’ä½œæˆ
        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)
        val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)
        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)
        
        print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:")
        print(f"  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_dataset)}æš")
        print(f"  æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(val_dataset)}æš")
        print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_dataset)}æš")
        
        return train_loader, val_loader, test_loader
    
    def train_epoch(self, train_loader, criterion, optimizer):
        """1ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’ã‚’å®Ÿè¡Œ"""
        self.model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(self.device), labels.to(self.device)
            
            # å‹¾é…ã‚’ãƒªã‚»ãƒƒãƒˆ
            optimizer.zero_grad()
            
            # é †ä¼æ’­
            outputs = self.model(images)
            loss = criterion(outputs, labels)
            
            # é€†ä¼æ’­
            loss.backward()
            optimizer.step()
            
            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        
        epoch_loss = running_loss / len(train_loader)
        epoch_acc = 100 * correct / total
        
        return epoch_loss, epoch_acc
    
    def validate_epoch(self, val_loader, criterion):
        """1ã‚¨ãƒãƒƒã‚¯ã®æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
        self.model.eval()
        running_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(self.device), labels.to(self.device)
                
                outputs = self.model(images)
                loss = criterion(outputs, labels)
                
                running_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        epoch_loss = running_loss / len(val_loader)
        epoch_acc = 100 * correct / total
        
        return epoch_loss, epoch_acc
    
    def train(self, train_loader, val_loader, num_epochs=20, learning_rate=0.001):
        """ãƒ¡ã‚¤ãƒ³ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—"""
        print(f"\nå­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
        print(f"ã‚¨ãƒãƒƒã‚¯æ•°: {num_epochs}")
        print(f"å­¦ç¿’ç‡: {learning_rate}")
        print("-" * 50)
        
        # æå¤±é–¢æ•°ã¨æœ€é©åŒ–å™¨ã‚’å®šç¾©
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.fc.parameters(), lr=learning_rate)
        
        best_val_acc = 0.0
        best_model_state = None
        
        for epoch in range(num_epochs):
            # å­¦ç¿’
            train_loss, train_acc = self.train_epoch(train_loader, criterion, optimizer)
            
            # æ¤œè¨¼
            val_loss, val_acc = self.validate_epoch(val_loader, criterion)
            
            # å±¥æ­´ã‚’è¨˜éŒ²
            self.history['train_loss'].append(train_loss)
            self.history['train_acc'].append(train_acc)
            self.history['val_loss'].append(val_loss)
            self.history['val_acc'].append(val_acc)
            
            # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_model_state = self.model.state_dict().copy()
            
            # å­¦ç¿’çŠ¶æ³ã‚’è¡¨ç¤º
            print(f'Epoch [{epoch+1:2d}/{num_epochs}] '
                  f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | '
                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')
        
        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        if best_model_state:
            self.model.load_state_dict(best_model_state)
        
        print(f"\nå­¦ç¿’å®Œäº†! æœ€é«˜æ¤œè¨¼ç²¾åº¦: {best_val_acc:.2f}%")
        return best_val_acc
    
    def evaluate(self, test_loader, class_names=['chihuahua', 'chikuwa']):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡"""
        self.model.eval()
        correct = 0
        total = 0
        class_correct = list(0. for i in range(len(class_names)))
        class_total = list(0. for i in range(len(class_names)))
        
        predictions = []
        true_labels = []
        
        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(self.device), labels.to(self.device)
                outputs = self.model(images)
                _, predicted = torch.max(outputs, 1)
                
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                # ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦ã‚’è¨ˆç®—
                c = (predicted == labels).squeeze()
                for i in range(labels.size(0)):
                    label = labels[i]
                    class_correct[label] += c[i].item()
                    class_total[label] += 1
                
                predictions.extend(predicted.cpu().numpy())
                true_labels.extend(labels.cpu().numpy())
        
        overall_acc = 100 * correct / total
        
        print(f"\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æœ€çµ‚è©•ä¾¡ ===")
        print(f"å…¨ä½“ç²¾åº¦: {overall_acc:.2f}%")
        print("\nã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦:")
        
        for i in range(len(class_names)):
            if class_total[i] > 0:
                acc = 100 * class_correct[i] / class_total[i]
                print(f"  {class_names[i]}: {acc:.2f}% ({int(class_correct[i])}/{int(class_total[i])})")
        
        return overall_acc, predictions, true_labels
    
    def plot_training_history(self, save_path='models/training_history.png'):
        """å­¦ç¿’å±¥æ­´ã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # æå¤±ã®ãƒ—ãƒ­ãƒƒãƒˆ
        ax1.plot(self.history['train_loss'], label='Train Loss', color='blue')
        ax1.plot(self.history['val_loss'], label='Val Loss', color='orange')
        ax1.set_title('Training and Validation Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # ç²¾åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆ
        ax2.plot(self.history['train_acc'], label='Train Accuracy', color='blue')
        ax2.plot(self.history['val_acc'], label='Val Accuracy', color='orange')
        ax2.set_title('Training and Validation Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"å­¦ç¿’å±¥æ­´ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")
    
    def save_model(self, save_path='models/chihuawa_chikuwa_classifier.pt'):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        save_dict = {
            'model_state_dict': self.model.state_dict(),
            'num_classes': self.num_classes,
            'history': self.history,
            'timestamp': datetime.now().isoformat()
        }
        
        torch.save(save_dict, save_path)
        print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")
    
    def load_model(self, load_path='models/chihuawa_chikuwa_classifier.pt'):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        checkpoint = torch.load(load_path, map_location=self.device)
        
        if self.model is None:
            self.create_model()
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.history = checkpoint.get('history', self.history)
        
        print(f"ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {load_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=== ãƒãƒ¯ãƒ¯ vs ãƒã‚¯ãƒ¯åˆ†é¡å™¨ Phase 3: AIãƒ¢ãƒ‡ãƒ«å­¦ç¿’ ===")
    
    # åˆ†é¡å™¨ã‚’åˆæœŸåŒ–
    classifier = ChihuawaChikuwaClassifier()
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
    model = classifier.create_model()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    train_loader, val_loader, test_loader = classifier.load_data()
    
    # å­¦ç¿’ã‚’å®Ÿè¡Œ
    best_val_acc = classifier.train(
        train_loader=train_loader,
        val_loader=val_loader,
        num_epochs=25,
        learning_rate=0.001
    )
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡
    test_acc, predictions, true_labels = classifier.evaluate(test_loader)
    
    # å­¦ç¿’å±¥æ­´ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    classifier.plot_training_history()
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    classifier.save_model()
    
    # çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    print(f"\n=== å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼ ===")
    print(f"æœ€é«˜æ¤œè¨¼ç²¾åº¦: {best_val_acc:.2f}%")
    print(f"æœ€çµ‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.2f}%")
    
    if test_acc >= 90.0:
        print("ğŸ‰ ç›®æ¨™ç²¾åº¦90%ã‚’é”æˆã—ã¾ã—ãŸï¼")
    else:
        print("ğŸ“Š ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã™")
    
    print(f"\nãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: models/chihuawa_chikuwa_classifier.pt")
    print(f"å­¦ç¿’å±¥æ­´ã‚°ãƒ©ãƒ•: models/training_history.png")


if __name__ == "__main__":
    main()